{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity Prediction\n",
    "\n",
    "In this notebook I will try to predict popularity, based on the tags used. Although predicting popularity just based on tags is fairly impossible and the fact that the dataset is not very big, it will be fun to fiddle with the data a bit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>film_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>num_speaker</th>\n",
       "      <th>published_date</th>\n",
       "      <th>...</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>speaker_occupation</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "      <th>impressions</th>\n",
       "      <th>positive_impressions</th>\n",
       "      <th>negative_impressions</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4553</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>60</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 865, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>Author/educator</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
       "      <td>47227110</td>\n",
       "      <td>93850.0</td>\n",
       "      <td>92712.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.441611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>265</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>977</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>43</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Al Gore: Averting the climate crisis</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 243, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>Climate advocate</td>\n",
       "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>https://www.ted.com/talks/al_gore_on_averting_...</td>\n",
       "      <td>3200520</td>\n",
       "      <td>2936.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>0.355374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>1286</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140739200</td>\n",
       "      <td>26</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>David Pogue: Simplicity sells</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 1725, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Technology columnist</td>\n",
       "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>https://www.ted.com/talks/david_pogue_says_sim...</td>\n",
       "      <td>1636292</td>\n",
       "      <td>2824.0</td>\n",
       "      <td>2473.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>0.393828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>1116</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140912000</td>\n",
       "      <td>35</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>Majora Carter: Greening the ghetto</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 1041, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Activist for environmental justice</td>\n",
       "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>https://www.ted.com/talks/majora_carter_s_tale...</td>\n",
       "      <td>1697550</td>\n",
       "      <td>3728.0</td>\n",
       "      <td>3572.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.443118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>1190</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140566400</td>\n",
       "      <td>48</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>Hans Rosling: The best stats you've ever seen</td>\n",
       "      <td>1</td>\n",
       "      <td>1151440680</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 2056, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Global health expert; data visionary</td>\n",
       "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
       "      <td>The best stats you've ever seen</td>\n",
       "      <td>https://www.ted.com/talks/hans_rosling_shows_t...</td>\n",
       "      <td>12005869</td>\n",
       "      <td>25620.0</td>\n",
       "      <td>25310.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.446907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments                                        description  duration  \\\n",
       "0      4553  Sir Ken Robinson makes an entertaining and pro...      1164   \n",
       "1       265  With the same humor and humanity he exuded in ...       977   \n",
       "2       124  New York Times columnist David Pogue takes aim...      1286   \n",
       "3       200  In an emotionally charged talk, MacArthur-winn...      1116   \n",
       "4       593  You've never seen data presented like this. Wi...      1190   \n",
       "\n",
       "     event   film_date  languages   main_speaker  \\\n",
       "0  TED2006  1140825600         60   Ken Robinson   \n",
       "1  TED2006  1140825600         43        Al Gore   \n",
       "2  TED2006  1140739200         26    David Pogue   \n",
       "3  TED2006  1140912000         35  Majora Carter   \n",
       "4  TED2006  1140566400         48   Hans Rosling   \n",
       "\n",
       "                                            name  num_speaker  published_date  \\\n",
       "0      Ken Robinson: Do schools kill creativity?            1      1151367060   \n",
       "1           Al Gore: Averting the climate crisis            1      1151367060   \n",
       "2                  David Pogue: Simplicity sells            1      1151367060   \n",
       "3             Majora Carter: Greening the ghetto            1      1151367060   \n",
       "4  Hans Rosling: The best stats you've ever seen            1      1151440680   \n",
       "\n",
       "   ...                                      related_talks  \\\n",
       "0  ...  [{'id': 865, 'hero': 'https://pe.tedcdn.com/im...   \n",
       "1  ...  [{'id': 243, 'hero': 'https://pe.tedcdn.com/im...   \n",
       "2  ...  [{'id': 1725, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "3  ...  [{'id': 1041, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "4  ...  [{'id': 2056, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "\n",
       "                     speaker_occupation  \\\n",
       "0                       Author/educator   \n",
       "1                      Climate advocate   \n",
       "2                  Technology columnist   \n",
       "3    Activist for environmental justice   \n",
       "4  Global health expert; data visionary   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['children', 'creativity', 'culture', 'dance',...   \n",
       "1  ['alternative energy', 'cars', 'climate change...   \n",
       "2  ['computers', 'entertainment', 'interface desi...   \n",
       "3  ['MacArthur grant', 'activism', 'business', 'c...   \n",
       "4  ['Africa', 'Asia', 'Google', 'demo', 'economic...   \n",
       "\n",
       "                             title  \\\n",
       "0      Do schools kill creativity?   \n",
       "1      Averting the climate crisis   \n",
       "2                 Simplicity sells   \n",
       "3              Greening the ghetto   \n",
       "4  The best stats you've ever seen   \n",
       "\n",
       "                                                 url     views  impressions  \\\n",
       "0  https://www.ted.com/talks/ken_robinson_says_sc...  47227110      93850.0   \n",
       "1  https://www.ted.com/talks/al_gore_on_averting_...   3200520       2936.0   \n",
       "2  https://www.ted.com/talks/david_pogue_says_sim...   1636292       2824.0   \n",
       "3  https://www.ted.com/talks/majora_carter_s_tale...   1697550       3728.0   \n",
       "4  https://www.ted.com/talks/hans_rosling_shows_t...  12005869      25620.0   \n",
       "\n",
       "   positive_impressions  negative_impressions  popularity  \n",
       "0               92712.0                1138.0    0.441611  \n",
       "1                2372.0                 564.0    0.355374  \n",
       "2                2473.0                 351.0    0.393828  \n",
       "3                3572.0                 156.0    0.443118  \n",
       "4               25310.0                 310.0    0.446907  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = pandas.read_csv('data/ted_updated.csv')\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets first use the JSON parse function oen the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseJsonInDataframe(df, columns):\n",
    "    for i in range(0, df.shape[0]):\n",
    "        for column in columns:\n",
    "            if (column in df and type(df.at[i, column]) is str):\n",
    "                df.at[i, column] = ast.literal_eval(df.at[i, column])\n",
    "\n",
    "parseJsonInDataframe(data_frame, [\"tags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all unique tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tags count: 416\n",
      "Max amaount of tags per sample: 32\n",
      "Min amaount of tags per sample: 1\n"
     ]
    }
   ],
   "source": [
    "unique_tags = set()\n",
    "max_tags_per_sample = 0\n",
    "min_tags_per_sample = 100\n",
    "\n",
    "for tags in data_frame.tags:\n",
    "    unique_tags.update(tags)\n",
    "    max_tags_per_sample = max(max_tags_per_sample, len(tags))\n",
    "    min_tags_per_sample = min(min_tags_per_sample, len(tags))\n",
    "    \n",
    "# Because sets don't have indices we need to make it list agian\n",
    "unique_tags = list(unique_tags)\n",
    "print(\"Unique tags count:\", len(unique_tags))\n",
    "print(\"Max amaount of tags per sample:\", max_tags_per_sample)\n",
    "print(\"Min amaount of tags per sample:\", min_tags_per_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use one-hot representation to prapare train/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "labels = []\n",
    "\n",
    "for i, row in data_frame.iterrows():\n",
    "    samples.append([unique_tags.index(tag) for tag in row[\"tags\"]])\n",
    "    labels.append(row[\"popularity\"])\n",
    "\n",
    "# Lets convert samples to one-hot representation\n",
    "for i, sample in enumerate(samples):\n",
    "    one_hot = np.zeros(len(unique_tags))\n",
    "    for tag in sample:\n",
    "        one_hot[tag] = 1\n",
    "    \n",
    "    samples[i] = one_hot\n",
    "\n",
    "# Shuffle the data\n",
    "samples, labels = shuffle(samples, labels, random_state=42)\n",
    "\n",
    "# Create train/test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(samples, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -1.0755872045831714\n"
     ]
    }
   ],
   "source": [
    "mlpr = MLPRegressor()\n",
    "mlpr.fit(X_train, y_train)\n",
    "mlpr_predicted = mlpr.predict(X_test)\n",
    "\n",
    "print(\"Score:\", r2_score(y_test, mlpr_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -0.06537931204834568\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=100)\n",
    "rfr.fit(X_train, y_train)\n",
    "rfr_predicted = rfr.predict(X_test)\n",
    "\n",
    "print(\"Score:\", r2_score(y_test, rfr_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -0.36976869743479424\n"
     ]
    }
   ],
   "source": [
    "adar = AdaBoostRegressor()\n",
    "adar.fit(X_train, y_train)\n",
    "adar_predicted = adar.predict(X_test)\n",
    "\n",
    "print(\"Score:\", r2_score(y_test, adar_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -0.897982628460644\n"
     ]
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(X_train, y_train)\n",
    "dtr_predicted = dtr.predict(X_test)\n",
    "\n",
    "print(\"Score:\", r2_score(y_test, dtr_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -1.955937527267203e+24\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_predicted = lr.predict(X_test)\n",
    "\n",
    "print(\"Score:\", r2_score(y_test, lr_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.08304069161957117\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_predicted = gbr.predict(X_test)\n",
    "\n",
    "print(\"Score:\", r2_score(y_test, gbr_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -0.2339003909938253\n"
     ]
    }
   ],
   "source": [
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "knr_predicted = knr.predict(X_test)\n",
    "\n",
    "print(\"Score:\", r2_score(y_test, knr_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are not very good (as expected). The best results were achieved with using gradinet tree boosting regressor. However, as you can see for all the regressors I used the default configuration. Which may not be the optimal one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try doing some \"ensambling\"\n",
    "\n",
    "Just compute the mean of all predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -3.991709239319396e+22\n"
     ]
    }
   ],
   "source": [
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)\n",
    "\n",
    "def ensamblePredict(data):\n",
    "    r1 = mlpr.predict(data)\n",
    "    r2 = rfr.predict(data)\n",
    "    r3 = adar.predict(data)\n",
    "    r4 = dtr.predict(data)\n",
    "    r5 = lr.predict(data)\n",
    "    r6 = gbr.predict(data)\n",
    "    r7 = knr.predict(data)\n",
    "    \n",
    "    \n",
    "    return [mean([r1[i], r2[i], r3[i], r4[i], r5[i], r6[i], r7[i]]) for i in range(0, len(data))]\n",
    "\n",
    "res = ensamblePredict(X_test)\n",
    "print(\"Score:\", r2_score(y_test, res))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not the regular way to implement ensambling. Usually ensambles are trained as such and not separetly. However, this is a good way to illustrate that via ensmabling we can achieve above average results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets try some parameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first define the parameters we want to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400, 450, 500], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_split': [2, 3, 4, 5], 'min_samples_leaf': [1, 2, 4]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 500, num = 10)]\n",
    "\n",
    "# Maximum tree depth\n",
    "max_depth = list(range(1, 11))\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 4, 5]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the parameters, lets use a random search algorithm for optimizing the hyper parameters. For the regressor I will use the one that scored the best result - GradientBoostingRegressor. The task is to see if we can achieve better results through hyperparameter optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.11241341416127681\n"
     ]
    }
   ],
   "source": [
    "regressor = GradientBoostingRegressor()\n",
    "\n",
    "regressor_random = RandomizedSearchCV(estimator = regressor, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "regressor_random.fit(X_train, y_train)\n",
    "pred = regressor_random.predict(X_test)\n",
    "\n",
    "print(\"Score:\", r2_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the results are a little bit better. Lets check the parameters chozen by the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Predicting popularity based simply on the keywords or tags used is not the most optimal way to do that. However, it was still a cool experiment. The results were as expected and got a little better through hyperparameter optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
